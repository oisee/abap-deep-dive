#!/usr/bin/env python3
"""
ABAP Deep Dive Technical Fact Checker
Verifies technical claims, code examples, and identifies missing content
"""

import os
import re
import json
from datetime import datetime
from pathlib import Path
import argparse

class ABAPFactChecker:
    def __init__(self, output_dir="factcheck"):
        self.output_dir = output_dir
        self.issues_dir = os.path.join(output_dir, "issues")
        self.todo_dir = os.path.join(output_dir, "todo")
        self.verified_dir = os.path.join(output_dir, "verified")
        
        # Create directories
        for dir_path in [self.issues_dir, self.todo_dir, self.verified_dir]:
            os.makedirs(dir_path, exist_ok=True)
            
        # Patterns to identify potential issues
        self.patterns = {
            'vague_statements': [
                r'–ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫',
                r'—á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ',
                r'–∫–∞–∫-—Ç–æ —Ç–∞–∫',
                r'–Ω–∞–≤–µ—Ä–Ω–æ–µ',
                r'–≤–æ–∑–º–æ–∂–Ω–æ',
                r'—É–ø—Ä–æ—â–µ–Ω–Ω–æ',
                r'–ø—Å–µ–≤–¥–æ–∫–æ–¥',
                r'—É—Å–ª–æ–≤–Ω–æ'
            ],
            'missing_examples': [
                r'[–ü–ø]—Ä–∏–º–µ—Ä:?\s*$',
                r'[–ù–Ω]–∞–ø—Ä–∏–º–µ—Ä:?\s*$',
                r'[–î–¥]–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è:?\s*$'
            ],
            'outdated_references': [
                r'SAP\s+(?:R/3|46C|470|ECC\s*6\.0)',
                r'—Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏',
                r'—Ä–∞–Ω—å—à–µ –±—ã–ª–æ'
            ],
            'technical_claims': [
                r'\d+\s*(?:–ú–ë|MB|–ì–ë|GB|–º—Å|ms|—Å–µ–∫|sec)',
                r'–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.*\d+',
                r'–±—ã—Å—Ç—Ä–µ–µ –≤\s*\d+',
                r'–º–µ–¥–ª–µ–Ω–Ω–µ–µ –≤\s*\d+'
            ],
            'code_blocks': [
                r'```(?:abap|sql|xml|json|yaml)',
                r'DATA:',
                r'SELECT\s+',
                r'METHOD\s+'
            ]
        }
        
        # Known facts database (could be loaded from external file)
        self.known_facts = {
            'processes': {
                'message_server': {
                    'unix': 'ms.sap<SID>',
                    'windows': 'msg_server.exe',
                    'port': '36<NN>'
                },
                'dispatcher': {
                    'unix': 'disp+work',
                    'windows': 'disp+work.exe'
                }
            },
            'memory_limits': {
                'em_initial_size_mb': {'min': 4096, 'default': 16384},
                'abap_heap_area_dia': {'max': 2000000000},
                'abap_heap_area_nondia': {'max': 0}
            },
            'architecture': {
                'sap_gui': 'thin client',
                'work_process_types': ['DIA', 'BTC', 'UPD', 'ENQ', 'SPO', 'V2', 'ICM']
            }
        }
        
    def extract_facts_from_chapter(self, content, chapter_name):
        """Extract technical claims and identify missing content"""
        facts = []
        todos = []
        fact_id = 1
        todo_id = 1
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            # Check for vague statements
            for pattern in self.patterns['vague_statements']:
                if re.search(pattern, line, re.IGNORECASE):
                    todos.append({
                        'id': f'TODO.{todo_id}',
                        'type': 'TODO_EXAMPLE',
                        'line': i + 1,
                        'text': line.strip(),
                        'reason': f'Vague statement: "{pattern}"',
                        'priority': 'MEDIUM'
                    })
                    todo_id += 1
            
            # Check for missing examples
            for pattern in self.patterns['missing_examples']:
                if re.search(pattern, line):
                    if i + 1 < len(lines) and not lines[i + 1].strip():
                        todos.append({
                            'id': f'TODO.{todo_id}',
                            'type': 'TODO_EXAMPLE',
                            'line': i + 1,
                            'text': line.strip(),
                            'reason': 'Example announced but missing',
                            'priority': 'HIGH'
                        })
                        todo_id += 1
            
            # Extract technical claims
            for pattern in self.patterns['technical_claims']:
                matches = re.finditer(pattern, line)
                for match in matches:
                    facts.append({
                        'id': f'F.{fact_id}',
                        'line': i + 1,
                        'claim': match.group(),
                        'context': line.strip(),
                        'needs_verification': True
                    })
                    fact_id += 1
            
            # Check for SAP GUI references
            if 'SAP GUI' in line or 'SAP-GUI' in line:
                if '—Ç–æ–ª—Å—Ç—ã–π –∫–ª–∏–µ–Ω—Ç' in line:
                    facts.append({
                        'id': f'F.{fact_id}',
                        'line': i + 1,
                        'claim': 'SAP GUI - —Ç–æ–ª—Å—Ç—ã–π –∫–ª–∏–µ–Ω—Ç',
                        'context': line.strip(),
                        'error': 'SAP GUI is a thin client, not thick client',
                        'severity': 'HIGH'
                    })
                    fact_id += 1
        
        return facts, todos
    
    def verify_code_examples(self, content):
        """Verify ABAP code examples for syntax and best practices"""
        code_issues = []
        
        # Extract code blocks
        code_pattern = r'```(?P<lang>abap|sql)?\n(?P<code>.*?)\n```'
        matches = re.finditer(code_pattern, content, re.DOTALL)
        
        for match in matches:
            lang = match.group('lang') or 'unknown'
            code = match.group('code')
            
            if lang == 'abap':
                # Basic ABAP syntax checks
                issues = self.check_abap_code(code)
                if issues:
                    code_issues.extend(issues)
            elif lang == 'sql':
                # Basic SQL checks
                issues = self.check_sql_code(code)
                if issues:
                    code_issues.extend(issues)
        
        return code_issues
    
    def check_abap_code(self, code):
        """Basic ABAP code verification"""
        issues = []
        
        # Check for common ABAP issues
        if 'SELECT *' in code:
            issues.append({
                'type': 'PERFORMANCE',
                'message': 'SELECT * should be avoided, specify fields explicitly',
                'severity': 'MEDIUM'
            })
        
        if 'LOOP AT' in code and 'WHERE' not in code:
            issues.append({
                'type': 'PERFORMANCE',
                'message': 'LOOP AT without WHERE clause - consider filtering',
                'severity': 'LOW'
            })
        
        # Check for obsolete syntax
        obsolete_patterns = {
            'MOVE': 'Use = operator instead of MOVE',
            'COMPUTE': 'COMPUTE is obsolete, use direct assignment',
            'HEADER LINE': 'Tables with HEADER LINE are obsolete'
        }
        
        for pattern, message in obsolete_patterns.items():
            if pattern in code:
                issues.append({
                    'type': 'OBSOLETE',
                    'message': message,
                    'severity': 'MEDIUM'
                })
        
        return issues
    
    def check_sql_code(self, code):
        """Basic SQL code verification"""
        issues = []
        
        if 'SELECT SINGLE' in code and 'ORDER BY' in code:
            issues.append({
                'type': 'LOGIC',
                'message': 'SELECT SINGLE with ORDER BY is contradictory',
                'severity': 'HIGH'
            })
        
        return issues
    
    def generate_factcheck_report(self, chapter_name, facts, todos, code_issues):
        """Generate fact-check report for a chapter"""
        
        # Calculate statistics
        critical_issues = len([f for f in facts if f.get('severity') == 'HIGH'])
        medium_issues = len([f for f in facts if f.get('severity') == 'MEDIUM'])
        
        # Determine overall status
        if critical_issues > 0:
            status = "üî¥ –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏"
        elif medium_issues > 3:
            status = "üü° –ú–∏–Ω–æ—Ä–Ω—ã–µ –ø—Ä–∞–≤–∫–∏"
        else:
            status = "üü¢ –ì–æ—Ç–æ–≤–æ"
        
        report = f"""# –§–∞–∫—Ç-—á–µ–∫: {chapter_name}
–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M')}
–°—Ç–∞—Ç—É—Å: {status}

## –°–≤–æ–¥–∫–∞
- –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {len(facts)}
- –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len([f for f in facts if 'error' in f])}
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫: {critical_issues}
- TODO items: {len(todos)}
- –ü—Ä–æ–±–ª–µ–º –≤ –∫–æ–¥–µ: {len(code_issues)}

"""
        
        # Add critical issues
        critical_facts = [f for f in facts if f.get('severity') == 'HIGH']
        if critical_facts:
            report += "## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (HIGH priority)\n"
            for fact in critical_facts:
                report += f"""### ‚ùå [{fact['id']}] {fact.get('error', '–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏')}
**–°—Ç—Ä–æ–∫–∞**: {fact['line']}
**–ù–∞–ø–∏—Å–∞–Ω–æ**: "{fact['context']}"
**–ü—Ä–æ–±–ª–µ–º–∞**: {fact.get('error', '–¢—Ä–µ–±—É–µ—Ç –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏')}

"""
        
        # Add medium issues
        medium_facts = [f for f in facts if f.get('severity') == 'MEDIUM']
        if medium_facts:
            report += "## –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (MEDIUM priority)\n"
            for fact in medium_facts:
                report += f"""### ‚ö†Ô∏è [{fact['id']}] {fact.get('claim', '')}
**–°—Ç—Ä–æ–∫–∞**: {fact['line']}
**–ö–æ–Ω—Ç–µ–∫—Å—Ç**: "{fact['context']}"

"""
        
        # Add code issues
        if code_issues:
            report += "## –ü—Ä–æ–±–ª–µ–º—ã –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –∫–æ–¥–∞\n"
            for issue in code_issues:
                severity_icon = "‚ùå" if issue['severity'] == 'HIGH' else "‚ö†Ô∏è"
                report += f"""### {severity_icon} {issue['type']}
**–ü—Ä–æ–±–ª–µ–º–∞**: {issue['message']}
**–í–∞–∂–Ω–æ—Å—Ç—å**: {issue['severity']}

"""
        
        return report
    
    def generate_todo_report(self, chapter_name, todos):
        """Generate TODO report for missing content"""
        
        report = f"""# TODO –ª–∏—Å—Ç: {chapter_name}
–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- –í—Å–µ–≥–æ TODO: {len(todos)}
- –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {len([t for t in todos if t['priority'] == 'HIGH'])}
- –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {len([t for t in todos if t['priority'] == 'MEDIUM'])}

"""
        
        # Group by priority
        for priority in ['HIGH', 'MEDIUM', 'LOW']:
            priority_todos = [t for t in todos if t['priority'] == priority]
            if priority_todos:
                priority_label = {
                    'HIGH': '–í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
                    'MEDIUM': '–°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
                    'LOW': '–ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç'
                }[priority]
                
                report += f"## {priority_label}\n"
                for todo in priority_todos:
                    report += f"""- [ ] [{todo['id']}] {todo['reason']}
  - **–°—Ç—Ä–æ–∫–∞ {todo['line']}**: {todo['text'][:80]}...
  - **–¢–∏–ø**: {todo['type']}

"""
        
        return report
    
    def process_chapter(self, chapter_path):
        """Process a single chapter file"""
        chapter_name = Path(chapter_path).stem
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è—é: {chapter_name}")
        
        with open(chapter_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract facts and TODOs
        facts, todos = self.extract_facts_from_chapter(content, chapter_name)
        
        # Verify code examples
        code_issues = self.verify_code_examples(content)
        
        # Generate reports
        factcheck_report = self.generate_factcheck_report(chapter_name, facts, todos, code_issues)
        todo_report = self.generate_todo_report(chapter_name, todos)
        
        # Save reports
        safe_name = re.sub(r'[^\w\-_\. ]', '_', chapter_name)
        
        factcheck_path = os.path.join(self.issues_dir, f"FACTCHECK_{safe_name}.md")
        with open(factcheck_path, 'w', encoding='utf-8') as f:
            f.write(factcheck_report)
        
        todo_path = os.path.join(self.todo_dir, f"TODO_{safe_name}.md")
        with open(todo_path, 'w', encoding='utf-8') as f:
            f.write(todo_report)
        
        print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {factcheck_path}")
        print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {todo_path}")
        
        return {
            'chapter': chapter_name,
            'facts': len(facts),
            'issues': len([f for f in facts if 'error' in f]),
            'todos': len(todos),
            'code_issues': len(code_issues)
        }

def main():
    parser = argparse.ArgumentParser(description='ABAP Deep Dive Technical Fact Checker')
    parser.add_argument('chapters', nargs='*', help='Chapter files to check (if not specified, checks all)')
    parser.add_argument('--output-dir', default='factcheck', help='Output directory for reports')
    
    args = parser.parse_args()
    
    checker = ABAPFactChecker(args.output_dir)
    
    # Get chapter files
    if args.chapters:
        chapter_files = args.chapters
    else:
        # Check all ADD chapter files
        chapter_files = [f for f in os.listdir('.') if f.startswith('ADD') and f.endswith('.md')]
        chapter_files.sort()
    
    if not chapter_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –≥–ª–∞–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return
    
    print(f"üîç ABAP Deep Dive Fact Checker")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}/")
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(chapter_files)}\n")
    
    # Process all chapters
    results = []
    for chapter_file in chapter_files:
        if os.path.exists(chapter_file):
            result = checker.process_chapter(chapter_file)
            results.append(result)
        else:
            print(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {chapter_file}")
    
    # Generate summary
    print("\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    total_facts = sum(r['facts'] for r in results)
    total_issues = sum(r['issues'] for r in results)
    total_todos = sum(r['todos'] for r in results)
    total_code_issues = sum(r['code_issues'] for r in results)
    
    print(f"  - –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {total_facts}")
    print(f"  - –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")
    print(f"  - TODO —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_todos}")
    print(f"  - –ü—Ä–æ–±–ª–µ–º –≤ –∫–æ–¥–µ: {total_code_issues}")
    
    # Save summary
    summary_path = os.path.join(args.output_dir, "README.md")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(f"""# ABAP Deep Dive - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–∞–∫—Ç-—á–µ–∫–∏–Ω–≥–∞

–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≥–ª–∞–≤: {len(results)}
- –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {total_facts}
- –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}
- TODO —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_todos}
- –ü—Ä–æ–±–ª–µ–º –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –∫–æ–¥–∞: {total_code_issues}

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≥–ª–∞–≤–∞–º
| –ì–ª–∞–≤–∞ | –§–∞–∫—Ç—ã | –ü—Ä–æ–±–ª–µ–º—ã | TODO | –ö–æ–¥ |
|-------|-------|----------|------|-----|
""")
        
        for result in results:
            f.write(f"| {result['chapter'][:50]}... | {result['facts']} | {result['issues']} | {result['todos']} | {result['code_issues']} |\n")
    
    print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {args.output_dir}/")

if __name__ == '__main__':
    main()